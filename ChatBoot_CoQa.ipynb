{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "igJ-LkeDLuZb",
        "outputId": "6fad43aa-116b-4043-939d-a4cfd99f470f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7895d9a3-885a-44cc-9719-3a0a6d927dd9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7895d9a3-885a-44cc-9719-3a0a6d927dd9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d jeromeblanchet/conversational-question-answering-dataset-coqa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5P0AL26M3gm",
        "outputId": "8123556e-afb1-45d1-894b-c72156bb2c1f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading conversational-question-answering-dataset-coqa.zip to /content\n",
            "\r  0% 0.00/10.2M [00:00<?, ?B/s]\n",
            "\r100% 10.2M/10.2M [00:00<00:00, 190MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip conversational-question-answering-dataset-coqa.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QTVqoPKNOGF",
        "outputId": "fdd06c86-1d45-4ee2-c5db-b331d8a1a4bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  conversational-question-answering-dataset-coqa.zip\n",
            "  inflating: coqa-dev-v1.0.json      \n",
            "  inflating: coqa-train-v1.0.json    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "G443SWpUZg1f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coqa = pd.read_json('/content/coqa-train-v1.0.json')\n",
        "coqa.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PM0wBaaxaOhe",
        "outputId": "e3c6b265-7d6f-4261-8197-cee0f173e7f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   version                                               data\n",
              "0        1  {'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...\n",
              "1        1  {'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...\n",
              "2        1  {'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...\n",
              "3        1  {'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...\n",
              "4        1  {'source': 'gutenberg', 'id': '3urfvvm165iantk..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d52198d6-5584-480c-b297-5d1536c1568e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>version</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'gutenberg', 'id': '3urfvvm165iantk...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d52198d6-5584-480c-b297-5d1536c1568e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d52198d6-5584-480c-b297-5d1536c1568e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d52198d6-5584-480c-b297-5d1536c1568e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coqa['data'][0]"
      ],
      "metadata": {
        "id": "QAUI8G2pY7P1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b6a2b0-b987-4d3b-f5ca-cf8bc8b72e96"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'wikipedia',\n",
              " 'id': '3zotghdk5ibi9cex97fepx7jetpso7',\n",
              " 'filename': 'Vatican_Library.txt',\n",
              " 'story': 'The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is the library of the Holy See, located in Vatican City. Formally established in 1475, although it is much older, it is one of the oldest libraries in the world and contains one of the most significant collections of historical texts. It has 75,000 codices from throughout history, as well as 1.1 million printed books, which include some 8,500 incunabula. \\n\\nThe Vatican Library is a research library for history, law, philosophy, science and theology. The Vatican Library is open to anyone who can document their qualifications and research needs. Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail. \\n\\nIn March 2014, the Vatican Library began an initial four-year project of digitising its collection of manuscripts, to be made available online. \\n\\nThe Vatican Secret Archives were separated from the library at the beginning of the 17th century; they contain another 150,000 items. \\n\\nScholars have traditionally divided the history of the library into five periods, Pre-Lateran, Lateran, Avignon, Pre-Vatican and Vatican. \\n\\nThe Pre-Lateran period, comprising the initial days of the library, dated from the earliest days of the Church. Only a handful of volumes survive from this period, though some are very significant.',\n",
              " 'questions': [{'input_text': 'When was the Vat formally opened?',\n",
              "   'turn_id': 1},\n",
              "  {'input_text': 'what is the library for?', 'turn_id': 2},\n",
              "  {'input_text': 'for what subjects?', 'turn_id': 3},\n",
              "  {'input_text': 'and?', 'turn_id': 4},\n",
              "  {'input_text': 'what was started in 2014?', 'turn_id': 5},\n",
              "  {'input_text': 'how do scholars divide the library?', 'turn_id': 6},\n",
              "  {'input_text': 'how many?', 'turn_id': 7},\n",
              "  {'input_text': 'what is the official name of the Vat?', 'turn_id': 8},\n",
              "  {'input_text': 'where is it?', 'turn_id': 9},\n",
              "  {'input_text': 'how many printed books does it contain?', 'turn_id': 10},\n",
              "  {'input_text': 'when were the Secret Archives moved from the rest of the library?',\n",
              "   'turn_id': 11},\n",
              "  {'input_text': 'how many items are in this secret collection?',\n",
              "   'turn_id': 12},\n",
              "  {'input_text': 'Can anyone use this library?', 'turn_id': 13},\n",
              "  {'input_text': 'what must be requested to view?', 'turn_id': 14},\n",
              "  {'input_text': 'what must be requested in person or by mail?',\n",
              "   'turn_id': 15},\n",
              "  {'input_text': 'of what books?', 'turn_id': 16},\n",
              "  {'input_text': 'What is the Vat the library of?', 'turn_id': 17},\n",
              "  {'input_text': 'How many books survived the Pre Lateran period?',\n",
              "   'turn_id': 18},\n",
              "  {'input_text': 'what is the point of the project started in 2014?',\n",
              "   'turn_id': 19},\n",
              "  {'input_text': 'what will this allow?', 'turn_id': 20}],\n",
              " 'answers': [{'span_start': 151,\n",
              "   'span_end': 179,\n",
              "   'span_text': 'Formally established in 1475',\n",
              "   'input_text': 'It was formally established in 1475',\n",
              "   'turn_id': 1},\n",
              "  {'span_start': 454,\n",
              "   'span_end': 494,\n",
              "   'span_text': 'he Vatican Library is a research library',\n",
              "   'input_text': 'research',\n",
              "   'turn_id': 2},\n",
              "  {'span_start': 457,\n",
              "   'span_end': 511,\n",
              "   'span_text': 'Vatican Library is a research library for history, law',\n",
              "   'input_text': 'history, and law',\n",
              "   'turn_id': 3},\n",
              "  {'span_start': 457,\n",
              "   'span_end': 545,\n",
              "   'span_text': 'Vatican Library is a research library for history, law, philosophy, science and theology',\n",
              "   'input_text': 'philosophy, science and theology',\n",
              "   'turn_id': 4},\n",
              "  {'span_start': 769,\n",
              "   'span_end': 879,\n",
              "   'span_text': 'March 2014, the Vatican Library began an initial four-year project of digitising its collection of manuscripts',\n",
              "   'input_text': 'a  project',\n",
              "   'turn_id': 5},\n",
              "  {'span_start': 1048,\n",
              "   'span_end': 1127,\n",
              "   'span_text': 'Scholars have traditionally divided the history of the library into five period',\n",
              "   'input_text': 'into periods',\n",
              "   'turn_id': 6},\n",
              "  {'span_start': 1048,\n",
              "   'span_end': 1128,\n",
              "   'span_text': 'Scholars have traditionally divided the history of the library into five periods',\n",
              "   'input_text': 'five',\n",
              "   'turn_id': 7},\n",
              "  {'span_start': 4,\n",
              "   'span_end': 94,\n",
              "   'span_text': 'Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, ',\n",
              "   'input_text': 'The Vatican Apostolic Library',\n",
              "   'turn_id': 8},\n",
              "  {'span_start': 94,\n",
              "   'span_end': 150,\n",
              "   'span_text': 'is the library of the Holy See, located in Vatican City.',\n",
              "   'input_text': 'in Vatican City',\n",
              "   'turn_id': 9},\n",
              "  {'span_start': 328,\n",
              "   'span_end': 412,\n",
              "   'span_text': ' It has 75,000 codices from throughout history, as well as 1.1 million printed books',\n",
              "   'input_text': '1.1 million',\n",
              "   'turn_id': 10},\n",
              "  {'span_start': 917,\n",
              "   'span_end': 1009,\n",
              "   'span_text': 'atican Secret Archives were separated from the library at the beginning of the 17th century;',\n",
              "   'input_text': 'at the beginning of the 17th century;',\n",
              "   'turn_id': 11},\n",
              "  {'span_start': 915,\n",
              "   'span_end': 1046,\n",
              "   'span_text': ' Vatican Secret Archives were separated from the library at the beginning of the 17th century; they contain another 150,000 items. ',\n",
              "   'input_text': '150,000',\n",
              "   'turn_id': 12},\n",
              "  {'span_start': 546,\n",
              "   'span_end': 643,\n",
              "   'span_text': ' The Vatican Library is open to anyone who can document their qualifications and research needs. ',\n",
              "   'input_text': 'anyone who can document their qualifications and research needs.',\n",
              "   'turn_id': 13},\n",
              "  {'span_start': -1,\n",
              "   'span_end': -1,\n",
              "   'span_text': 'unknown',\n",
              "   'input_text': 'unknown',\n",
              "   'turn_id': 14,\n",
              "   'bad_turn': 'true'},\n",
              "  {'span_start': 643,\n",
              "   'span_end': 764,\n",
              "   'span_text': 'Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail. ',\n",
              "   'input_text': 'Photocopies',\n",
              "   'turn_id': 15},\n",
              "  {'span_start': 644,\n",
              "   'span_end': 724,\n",
              "   'span_text': 'hotocopies for private study of pages from books published between 1801 and 1990',\n",
              "   'input_text': 'only books published between 1801 and 1990',\n",
              "   'turn_id': 16},\n",
              "  {'span_start': 78,\n",
              "   'span_end': 125,\n",
              "   'span_text': 'simply the Vat, is the library of the Holy See,',\n",
              "   'input_text': 'the Holy See',\n",
              "   'turn_id': 17},\n",
              "  {'span_start': 1192,\n",
              "   'span_end': 1384,\n",
              "   'span_text': 'Pre-Lateran period, comprising the initial days of the library, dated from the earliest days of the Church. Only a handful of volumes survive from this period, though some are very significant',\n",
              "   'input_text': 'a handful of volumes',\n",
              "   'turn_id': 18},\n",
              "  {'span_start': 785,\n",
              "   'span_end': 881,\n",
              "   'span_text': 'Vatican Library began an initial four-year project of digitising its collection of manuscripts, ',\n",
              "   'input_text': 'digitising manuscripts',\n",
              "   'turn_id': 19},\n",
              "  {'span_start': 868,\n",
              "   'span_end': 910,\n",
              "   'span_text': 'manuscripts, to be made available online. ',\n",
              "   'input_text': 'them to be viewed online.',\n",
              "   'turn_id': 20}],\n",
              " 'name': 'Vatican_Library.txt'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coqa['data'][0].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhPsiSZhbYh2",
        "outputId": "703c84eb-bb35-4c60-9be7-201105c33d9a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['source', 'id', 'filename', 'story', 'questions', 'answers', 'name'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"text\",\"question\",\"answer\"]\n",
        "\n",
        "comp_list = []\n",
        "for index, row in coqa.iterrows():\n",
        "    for i in range(len(row[\"data\"][\"questions\"])):\n",
        "        temp_list = []\n",
        "        temp_list.append(row[\"data\"][\"story\"])\n",
        "        temp_list.append(row[\"data\"][\"questions\"][i][\"input_text\"])\n",
        "        temp_list.append(row[\"data\"][\"answers\"][i][\"input_text\"])\n",
        "        comp_list.append(temp_list)\n",
        "\n",
        "new_df = pd.DataFrame(comp_list, columns=cols) "
      ],
      "metadata": {
        "id": "jhe5F0tqblb7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.to_csv(\"CoQA_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "-EqOCryjbnvl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"CoQA_data.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "O5Q4egpibrre",
        "outputId": "758efbd1-78f2-49e5-a8a1-dea3444aafa8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  The Vatican Apostolic Library (), more commonl...   \n",
              "1  The Vatican Apostolic Library (), more commonl...   \n",
              "2  The Vatican Apostolic Library (), more commonl...   \n",
              "3  The Vatican Apostolic Library (), more commonl...   \n",
              "4  The Vatican Apostolic Library (), more commonl...   \n",
              "\n",
              "                            question                               answer  \n",
              "0  When was the Vat formally opened?  It was formally established in 1475  \n",
              "1           what is the library for?                             research  \n",
              "2                 for what subjects?                     history, and law  \n",
              "3                               and?     philosophy, science and theology  \n",
              "4          what was started in 2014?                           a  project  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f89bef6-cb0e-43c9-a2e8-83e426dccfa3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>When was the Vat formally opened?</td>\n",
              "      <td>It was formally established in 1475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>what is the library for?</td>\n",
              "      <td>research</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>for what subjects?</td>\n",
              "      <td>history, and law</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>and?</td>\n",
              "      <td>philosophy, science and theology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>what was started in 2014?</td>\n",
              "      <td>a  project</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f89bef6-cb0e-43c9-a2e8-83e426dccfa3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f89bef6-cb0e-43c9-a2e8-83e426dccfa3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f89bef6-cb0e-43c9-a2e8-83e426dccfa3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of question and answers: \", len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvdIi5pPbxCk",
        "outputId": "d6579c11-e5fe-40cd-f4c4-e34fe869065c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of question and answers:  108647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertForQuestionAnswering\n",
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "ajomIGoFb5_t"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFBertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CohhrXbb-eA",
        "outputId": "3754e93a-99f0-47ae-c116-bf3ede65a5d6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
            "\n",
            "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_num = np.random.randint(0,len(data))\n",
        "\n",
        "question = data[\"question\"][random_num]\n",
        "text = data[\"text\"][random_num]"
      ],
      "metadata": {
        "id": "HhDgftL7cDzs"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_ek-RNnfOtR",
        "outputId": "2f1d6d9a-ce6f-40b3-9884-1609527f206b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29388"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(question, text, return_tensors=\"tf\")\n",
        "input_ids.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDa9VfVthK1x",
        "outputId": "8c5b43a9-ec6d-4997-c96a-043b73166e40"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids.input_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IerYBP3Xglge",
        "outputId": "30f37db5-f405-4e75-c786-2631a5899486"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(459,), dtype=int32, numpy=\n",
              "array([  101,  2054,  2265,  1029,   102,  1006, 13229,  1007,  1011,\n",
              "        1011, 17709,  5686,  7723,  2003,  2242,  1997,  1037,  2542,\n",
              "        5722,  2426, 10205,  1997,  4126,  4349,  1012,  1037,  5440,\n",
              "        1997,  8817,  1997,  8141,  1010,  1037,  5394,  2000,  7644,\n",
              "        1997,  4898,  1010,  2002,  1005,  1055,  2042,  2170,  1000,\n",
              "        2637,  1005,  1055,  4602,  4126,  3213,  1012,  1000,  1996,\n",
              "        6564,  1011,  2095,  2214,  3166,  2038,  2042,  3015,  2190,\n",
              "       23836,  2075,  2808,  2005,  8442,  2086,  1010,  3262,  2530,\n",
              "        2015,  1998,  4126,  6002,  1012,  2116,  1997,  2068,  2031,\n",
              "        2042,  2357,  2046,  2718,  5691,  1010,  2164,  1000,  1017,\n",
              "        1024,  2184,  2000,  9805,  2863,  1010,  1000,  1000,  2131,\n",
              "        2460,  2100,  1000,  1998,  1000,  2041,  1997,  4356,  1012,\n",
              "        1000,  2085,  1010,  7723,  5651,  2000,  2028,  1997,  2010,\n",
              "        5440,  3494,  1999,  2010, 14751,  2338,  1010,  2010, 24634,\n",
              "        3117,  2000,  2022,  6635,  1010,  4159,  3432,  1010,  1000,\n",
              "        4097,  5802,  1012,  1000,  2008,  2052,  2022,  1057,  1012,\n",
              "        1055,  1012,  8610,  4097,  5802,  2445,  2015,  1012,  1996,\n",
              "        4201,  2067,  1010, 26261, 25656,  1011,  4147,  2375,  2386,\n",
              "        2034,  2596,  1999,  7723,  1005,  1055,  6002,  1010,  1000,\n",
              "        4013, 13663,  1000,  1998,  1000,  5559,  1996,  9680,  1000,\n",
              "        1998,  2153,  1999,  1996,  2541,  2460,  2466,  1010,  1000,\n",
              "        2543,  1999,  1996,  4920,  1000,  2029,  2150,  1996,  3978,\n",
              "        2005,  1996,  2718,  2694,  2265,  1010,  1000, 15123,  1010,\n",
              "        1000,  4626, 10805, 19330, 22571,  4819,  2102,  2004,  1996,\n",
              "        2516,  2839,  1012,  1996,  3364,  1998,  1996,  2265,  2024,\n",
              "        3045,  2058,  4599,  1010,  4401,  1998,  7723,  2370,  1012,\n",
              "        2061,  2172,  2061,  2008,  7723,  2038,  2513,  2000,  3015,\n",
              "        2055,  1000,  4097,  5802,  1012,  1000,  1996,  2338,  2074,\n",
              "        2718,  3573, 15475,  1996,  2168,  2733,  1996,  2265,  2018,\n",
              "        2049,  2353,  2161,  6765,  1012,  7723,  1010, 24665, 20113,\n",
              "        1998, 14477,  4757, 24270,  1010,  3065,  2053,  5751,  1997,\n",
              "       18068,  2091,  2012,  2023,  2391,  1999,  2010,  2476,  1012,\n",
              "        1996,  3166,  3764,  2000, 13229,  2013,  2010,  2188,  1999,\n",
              "        4174,  1012,  1996,  2206,  2003,  2019,  5493, 24051,  1012,\n",
              "       13229,  1024,  2054,  2716,  2017,  2067,  2000,  4097,  5802,\n",
              "        1029,  7723,  1024,  1045,  1005,  2310,  2467,  4669,  2032,\n",
              "        1012,  2002,  1005,  1055,  2074,  2028,  1997,  2026, 20672,\n",
              "        1012,  2085,  2043,  1045,  2156,  2032,  2006,  1996,  3898,\n",
              "        1045,  2064,  1005,  1056,  2903,  2009,  1012,  2002,  4490,\n",
              "        3599,  1996,  2126,  1045,  4339,  2032,  1012,  2002,  1005,\n",
              "        1055,  2061,  4201,  2067,  1998,  2002,  2467,  2038,  1996,\n",
              "        2190,  2240,  1999,  1996,  3496,  1012,  2002,  1005,  1055,\n",
              "        3819,  1010,  2879,  1012,  1996,  2126,  2002,  7566,  1045,\n",
              "        2963,  2032,  2074,  1996,  2126,  1045,  2657,  2032,  2043,\n",
              "        1045,  1005,  1049,  3015,  2009,  1012,  2002,  1005,  1055,\n",
              "        2785,  1997,  4201,  2067,  2021,  2065,  2017,  2655,  2032,\n",
              "        2006,  2505,  1010,  2002,  2758,  1010,  1000,  2065,  1045,\n",
              "        2031,  2000,  4139,  2026,  3282,  1045,  2097,  5607,  2000,\n",
              "        3102,  1010,  1000,  1998,  2002,  1005,  1055,  3809,  2055,\n",
              "        2008,  2021,  2002,  2987,  1005,  1056,  2031,  2000,  2614,\n",
              "        2008,  3809,  1010,  2002,  2074,  2163,  2009,  1012,   102],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The input has a total of {} tokens.\".format(len(input_ids.input_ids[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn1ytnqHgpGY",
        "outputId": "67d30028-59d5-4e62-d481-50ef7707a156"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input has a total of 459 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(input_ids.input_ids[0])\n",
        "\n",
        "for token, id in zip(tokens, input_ids.input_ids[0]):\n",
        "    print('{:8}{:8,}'.format(token,id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8SXQAb0iIqL",
        "outputId": "96d922df-6d4b-4187-9381-fec9ea4ffc8a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]        101\n",
            "what       2,054\n",
            "show       2,265\n",
            "?          1,029\n",
            "[SEP]        102\n",
            "(          1,006\n",
            "cnn       13,229\n",
            ")          1,007\n",
            "-          1,011\n",
            "-          1,011\n",
            "elm       17,709\n",
            "##ore      5,686\n",
            "leonard    7,723\n",
            "is         2,003\n",
            "something   2,242\n",
            "of         1,997\n",
            "a          1,037\n",
            "living     2,542\n",
            "legend     5,722\n",
            "among      2,426\n",
            "lovers    10,205\n",
            "of         1,997\n",
            "crime      4,126\n",
            "fiction    4,349\n",
            ".          1,012\n",
            "a          1,037\n",
            "favorite   5,440\n",
            "of         1,997\n",
            "millions   8,817\n",
            "of         1,997\n",
            "readers    8,141\n",
            ",          1,010\n",
            "a          1,037\n",
            "hero       5,394\n",
            "to         2,000\n",
            "scores     7,644\n",
            "of         1,997\n",
            "writers    4,898\n",
            ",          1,010\n",
            "he         2,002\n",
            "'          1,005\n",
            "s          1,055\n",
            "been       2,042\n",
            "called     2,170\n",
            "\"          1,000\n",
            "america    2,637\n",
            "'          1,005\n",
            "s          1,055\n",
            "greatest   4,602\n",
            "crime      4,126\n",
            "writer     3,213\n",
            ".          1,012\n",
            "\"          1,000\n",
            "the        1,996\n",
            "86         6,564\n",
            "-          1,011\n",
            "year       2,095\n",
            "old        2,214\n",
            "author     3,166\n",
            "has        2,038\n",
            "been       2,042\n",
            "writing    3,015\n",
            "best       2,190\n",
            "##sell    23,836\n",
            "##ing      2,075\n",
            "books      2,808\n",
            "for        2,005\n",
            "sixty      8,442\n",
            "years      2,086\n",
            ",          1,010\n",
            "mostly     3,262\n",
            "western    2,530\n",
            "##s        2,015\n",
            "and        1,998\n",
            "crime      4,126\n",
            "novels     6,002\n",
            ".          1,012\n",
            "many       2,116\n",
            "of         1,997\n",
            "them       2,068\n",
            "have       2,031\n",
            "been       2,042\n",
            "turned     2,357\n",
            "into       2,046\n",
            "hit        2,718\n",
            "movies     5,691\n",
            ",          1,010\n",
            "including   2,164\n",
            "\"          1,000\n",
            "3          1,017\n",
            ":          1,024\n",
            "10         2,184\n",
            "to         2,000\n",
            "yu         9,805\n",
            "##ma       2,863\n",
            ",          1,010\n",
            "\"          1,000\n",
            "\"          1,000\n",
            "get        2,131\n",
            "short      2,460\n",
            "##y        2,100\n",
            "\"          1,000\n",
            "and        1,998\n",
            "\"          1,000\n",
            "out        2,041\n",
            "of         1,997\n",
            "sight      4,356\n",
            ".          1,012\n",
            "\"          1,000\n",
            "now        2,085\n",
            ",          1,010\n",
            "leonard    7,723\n",
            "returns    5,651\n",
            "to         2,000\n",
            "one        2,028\n",
            "of         1,997\n",
            "his        2,010\n",
            "favorite   5,440\n",
            "characters   3,494\n",
            "in         1,999\n",
            "his        2,010\n",
            "newest    14,751\n",
            "book       2,338\n",
            ",          1,010\n",
            "his        2,010\n",
            "45th      24,634\n",
            "novel      3,117\n",
            "to         2,000\n",
            "be         2,022\n",
            "exact      6,635\n",
            ",          1,010\n",
            "titled     4,159\n",
            "simply     3,432\n",
            ",          1,010\n",
            "\"          1,000\n",
            "ray        4,097\n",
            "##lan      5,802\n",
            ".          1,012\n",
            "\"          1,000\n",
            "that       2,008\n",
            "would      2,052\n",
            "be         2,022\n",
            "u          1,057\n",
            ".          1,012\n",
            "s          1,055\n",
            ".          1,012\n",
            "marshal    8,610\n",
            "ray        4,097\n",
            "##lan      5,802\n",
            "given      2,445\n",
            "##s        2,015\n",
            ".          1,012\n",
            "the        1,996\n",
            "laid       4,201\n",
            "back       2,067\n",
            ",          1,010\n",
            "ste       26,261\n",
            "##tson    25,656\n",
            "-          1,011\n",
            "wearing    4,147\n",
            "law        2,375\n",
            "##man      2,386\n",
            "first      2,034\n",
            "appeared   2,596\n",
            "in         1,999\n",
            "leonard    7,723\n",
            "'          1,005\n",
            "s          1,055\n",
            "novels     6,002\n",
            ",          1,010\n",
            "\"          1,000\n",
            "pro        4,013\n",
            "##nto     13,663\n",
            "\"          1,000\n",
            "and        1,998\n",
            "\"          1,000\n",
            "riding     5,559\n",
            "the        1,996\n",
            "rap        9,680\n",
            "\"          1,000\n",
            "and        1,998\n",
            "again      2,153\n",
            "in         1,999\n",
            "the        1,996\n",
            "2001       2,541\n",
            "short      2,460\n",
            "story      2,466\n",
            ",          1,010\n",
            "\"          1,000\n",
            "fire       2,543\n",
            "in         1,999\n",
            "the        1,996\n",
            "hole       4,920\n",
            "\"          1,000\n",
            "which      2,029\n",
            "became     2,150\n",
            "the        1,996\n",
            "basis      3,978\n",
            "for        2,005\n",
            "the        1,996\n",
            "hit        2,718\n",
            "tv         2,694\n",
            "show       2,265\n",
            ",          1,010\n",
            "\"          1,000\n",
            "justified  15,123\n",
            ",          1,010\n",
            "\"          1,000\n",
            "starring   4,626\n",
            "timothy   10,805\n",
            "ol        19,330\n",
            "##yp      22,571\n",
            "##han      4,819\n",
            "##t        2,102\n",
            "as         2,004\n",
            "the        1,996\n",
            "title      2,516\n",
            "character   2,839\n",
            ".          1,012\n",
            "the        1,996\n",
            "actor      3,364\n",
            "and        1,998\n",
            "the        1,996\n",
            "show       2,265\n",
            "are        2,024\n",
            "winning    3,045\n",
            "over       2,058\n",
            "fans       4,599\n",
            ",          1,010\n",
            "critics    4,401\n",
            "and        1,998\n",
            "leonard    7,723\n",
            "himself    2,370\n",
            ".          1,012\n",
            "so         2,061\n",
            "much       2,172\n",
            "so         2,061\n",
            "that       2,008\n",
            "leonard    7,723\n",
            "has        2,038\n",
            "returned   2,513\n",
            "to         2,000\n",
            "writing    3,015\n",
            "about      2,055\n",
            "\"          1,000\n",
            "ray        4,097\n",
            "##lan      5,802\n",
            ".          1,012\n",
            "\"          1,000\n",
            "the        1,996\n",
            "book       2,338\n",
            "just       2,074\n",
            "hit        2,718\n",
            "store      3,573\n",
            "shelves   15,475\n",
            "the        1,996\n",
            "same       2,168\n",
            "week       2,733\n",
            "the        1,996\n",
            "show       2,265\n",
            "had        2,018\n",
            "its        2,049\n",
            "third      2,353\n",
            "season     2,161\n",
            "premiere   6,765\n",
            ".          1,012\n",
            "leonard    7,723\n",
            ",          1,010\n",
            "gr        24,665\n",
            "##acious  20,113\n",
            "and        1,998\n",
            "una       14,477\n",
            "##ss       4,757\n",
            "##uming   24,270\n",
            ",          1,010\n",
            "shows      3,065\n",
            "no         2,053\n",
            "signs      5,751\n",
            "of         1,997\n",
            "slowing   18,068\n",
            "down       2,091\n",
            "at         2,012\n",
            "this       2,023\n",
            "point      2,391\n",
            "in         1,999\n",
            "his        2,010\n",
            "career     2,476\n",
            ".          1,012\n",
            "the        1,996\n",
            "author     3,166\n",
            "spoke      3,764\n",
            "to         2,000\n",
            "cnn       13,229\n",
            "from       2,013\n",
            "his        2,010\n",
            "home       2,188\n",
            "in         1,999\n",
            "michigan   4,174\n",
            ".          1,012\n",
            "the        1,996\n",
            "following   2,206\n",
            "is         2,003\n",
            "an         2,019\n",
            "edited     5,493\n",
            "transcript  24,051\n",
            ".          1,012\n",
            "cnn       13,229\n",
            ":          1,024\n",
            "what       2,054\n",
            "brought    2,716\n",
            "you        2,017\n",
            "back       2,067\n",
            "to         2,000\n",
            "ray        4,097\n",
            "##lan      5,802\n",
            "?          1,029\n",
            "leonard    7,723\n",
            ":          1,024\n",
            "i          1,045\n",
            "'          1,005\n",
            "ve         2,310\n",
            "always     2,467\n",
            "liked      4,669\n",
            "him        2,032\n",
            ".          1,012\n",
            "he         2,002\n",
            "'          1,005\n",
            "s          1,055\n",
            "just       2,074\n",
            "one        2,028\n",
            "of         1,997\n",
            "my         2,026\n",
            "favorites  20,672\n",
            ".          1,012\n",
            "now        2,085\n",
            "when       2,043\n",
            "i          1,045\n",
            "see        2,156\n",
            "him        2,032\n",
            "on         2,006\n",
            "the        1,996\n",
            "screen     3,898\n",
            "i          1,045\n",
            "can        2,064\n",
            "'          1,005\n",
            "t          1,056\n",
            "believe    2,903\n",
            "it         2,009\n",
            ".          1,012\n",
            "he         2,002\n",
            "acts       4,490\n",
            "exactly    3,599\n",
            "the        1,996\n",
            "way        2,126\n",
            "i          1,045\n",
            "write      4,339\n",
            "him        2,032\n",
            ".          1,012\n",
            "he         2,002\n",
            "'          1,005\n",
            "s          1,055\n",
            "so         2,061\n",
            "laid       4,201\n",
            "back       2,067\n",
            "and        1,998\n",
            "he         2,002\n",
            "always     2,467\n",
            "has        2,038\n",
            "the        1,996\n",
            "best       2,190\n",
            "line       2,240\n",
            "in         1,999\n",
            "the        1,996\n",
            "scene      3,496\n",
            ".          1,012\n",
            "he         2,002\n",
            "'          1,005\n",
            "s          1,055\n",
            "perfect    3,819\n",
            ",          1,010\n",
            "boy        2,879\n",
            ".          1,012\n",
            "the        1,996\n",
            "way        2,126\n",
            "he         2,002\n",
            "talks      7,566\n",
            "i          1,045\n",
            "hear       2,963\n",
            "him        2,032\n",
            "just       2,074\n",
            "the        1,996\n",
            "way        2,126\n",
            "i          1,045\n",
            "heard      2,657\n",
            "him        2,032\n",
            "when       2,043\n",
            "i          1,045\n",
            "'          1,005\n",
            "m          1,049\n",
            "writing    3,015\n",
            "it         2,009\n",
            ".          1,012\n",
            "he         2,002\n",
            "'          1,005\n",
            "s          1,055\n",
            "kind       2,785\n",
            "of         1,997\n",
            "laid       4,201\n",
            "back       2,067\n",
            "but        2,021\n",
            "if         2,065\n",
            "you        2,017\n",
            "call       2,655\n",
            "him        2,032\n",
            "on         2,006\n",
            "anything   2,505\n",
            ",          1,010\n",
            "he         2,002\n",
            "says       2,758\n",
            ",          1,010\n",
            "\"          1,000\n",
            "if         2,065\n",
            "i          1,045\n",
            "have       2,031\n",
            "to         2,000\n",
            "pull       4,139\n",
            "my         2,026\n",
            "gun        3,282\n",
            "i          1,045\n",
            "will       2,097\n",
            "shoot      5,607\n",
            "to         2,000\n",
            "kill       3,102\n",
            ",          1,010\n",
            "\"          1,000\n",
            "and        1,998\n",
            "he         2,002\n",
            "'          1,005\n",
            "s          1,055\n",
            "serious    3,809\n",
            "about      2,055\n",
            "that       2,008\n",
            "but        2,021\n",
            "he         2,002\n",
            "doesn      2,987\n",
            "'          1,005\n",
            "t          1,056\n",
            "have       2,031\n",
            "to         2,000\n",
            "sound      2,614\n",
            "that       2,008\n",
            "serious    3,809\n",
            ",          1,010\n",
            "he         2,002\n",
            "just       2,074\n",
            "states     2,163\n",
            "it         2,009\n",
            ".          1,012\n",
            "[SEP]        102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids.token_type_ids[0]    #Where 0's correpond to question tokens and 1's to context tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkJ9AppKiV3z",
        "outputId": "439af70b-f22e-44cc-c9da-c16b989a4427"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(459,), dtype=int32, numpy=\n",
              "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(input_ids)"
      ],
      "metadata": {
        "id": "Z9y-pKwfib3E"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.start_logits)\n",
        "print('\\n')\n",
        "print(output.end_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjXRM24MiuGJ",
        "outputId": "364d9560-2db2-403a-fa0b-6f2ff665b945"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.96938336 -4.945085   -8.391359   -9.309101    0.9693804  -6.896672\n",
            "  -3.6343331  -8.780928   -7.327328   -7.7984157  -5.2561417  -8.230055\n",
            "  -5.1379857  -8.726229   -7.2613993  -9.092161   -8.1635895  -7.254375\n",
            "  -8.012297   -8.77238    -7.26429    -8.662228   -4.251384   -7.3385677\n",
            "  -9.347054   -7.478221   -7.099795   -8.750254   -7.5264087  -8.873885\n",
            "  -7.992382   -9.289098   -7.759342   -8.19162    -8.875092   -8.097706\n",
            "  -9.043478   -7.929871   -9.169423   -6.738127   -8.784195   -8.717615\n",
            "  -8.417713   -8.254398   -6.8623924  -5.830492   -7.9834275  -8.147529\n",
            "  -7.2250786  -6.285223   -7.661238   -8.65226    -8.910417   -7.1059246\n",
            "  -6.679006   -8.167076   -8.700924   -8.458836   -7.205531   -7.9778256\n",
            "  -8.141532   -7.2472134  -7.2914357  -8.154713   -8.895203   -7.0017657\n",
            "  -8.390167   -7.712894   -8.546755   -9.008246   -7.634974   -7.0369453\n",
            "  -8.886316   -8.663387   -6.411747   -7.5073     -8.615711   -7.1074414\n",
            "  -8.406      -8.355878   -7.916001   -7.9183755  -7.0297112  -8.372577\n",
            "  -6.5011735  -6.2835674  -9.054023   -8.181747   -7.3466687  -7.014444\n",
            "  -8.98213    -8.6882925  -8.714083   -8.552055   -8.977343   -9.100359\n",
            "  -9.163807   -7.5892234  -7.214383   -8.797837   -9.03994    -9.227845\n",
            "  -8.664868   -7.5592313  -6.846803   -8.704637   -7.9764004  -8.139356\n",
            "  -8.842174   -6.123524   -8.332758   -4.1460967  -6.296122   -7.7416635\n",
            "  -5.7700305  -7.6912193  -6.6861596  -6.470363   -5.1565385  -6.392563\n",
            "  -4.140359   -4.8252664  -4.444882   -8.748062   -5.5052443  -5.1056037\n",
            "  -5.001424   -8.330393   -8.604133   -7.9410257  -8.643371   -6.4622145\n",
            "  -6.4580636  -8.40785    -4.8930387  -2.0710385  -5.698829   -6.808831\n",
            "  -8.291991   -5.7084465  -6.8336706  -7.877889   -3.5556512  -8.383453\n",
            "  -7.0710473  -7.5581613  -4.41246    -2.753722   -6.632923   -6.3579764\n",
            "  -7.385636   -6.9631696  -5.517796   -6.0158887  -8.28656    -8.543462\n",
            "  -5.9859605  -7.9530816  -8.518958   -7.8560967  -5.488351   -7.144778\n",
            "  -5.978471   -6.6570573  -8.314955   -7.255629   -7.7055373  -8.602645\n",
            "  -6.2046056  -8.81875    -6.62707    -6.210786   -8.236068   -9.039729\n",
            "  -8.56192    -6.768948   -6.0611496  -7.958775   -8.007242   -8.766878\n",
            "  -8.481043   -6.5203834  -6.652481   -6.054277   -3.7464473  -5.2775702\n",
            "  -6.0655265  -8.457581   -4.3192964  -3.8611379  -7.6154876  -7.5448456\n",
            "  -6.168778   -7.8424416  -6.2150044  -5.182739   -4.824557   -4.437947\n",
            "  -6.74479    -2.845326   -3.5003088  -3.9305458  -5.3560376  -6.221597\n",
            "  -0.34137157  2.1903436  -6.9567394  -5.3286257  -5.8234534  -5.1613913\n",
            "  -7.5016503  -8.376233   -7.8135495  -7.627703   -8.414137   -7.7723293\n",
            "  -8.059079   -6.748071   -6.2491856  -5.1098537  -5.2775664  -7.349087\n",
            "  -4.2532763  -5.584667   -5.5489287  -3.5938182  -8.115145   -5.5997396\n",
            "  -8.834334   -5.7456794  -8.951483   -6.703748   -7.9573216  -6.2014084\n",
            "  -7.3177366  -8.153841   -8.537112   -8.2770195  -5.577741   -7.891931\n",
            "  -6.085425   -7.7605805  -5.3318872  -8.320325   -6.5466957  -3.0446076\n",
            "  -6.119166   -6.6910577  -8.835245   -3.9916334  -3.9265823  -7.427465\n",
            "  -7.055626   -7.901914   -7.4962173  -7.668446   -7.311064   -6.8993225\n",
            "  -4.8919654  -6.3876204  -6.35482    -5.59395    -3.28724    -6.15931\n",
            "  -5.8226132  -6.5404406  -5.32229    -9.326504   -8.195263   -9.016673\n",
            "  -9.254344   -8.229784   -9.261892   -9.361444   -9.494537   -7.5403476\n",
            "  -8.1726055  -8.715931   -9.239728   -7.9818673  -9.11748    -8.954707\n",
            "  -8.8993225  -8.907556   -8.75965    -7.9951696  -7.2216363  -7.573313\n",
            "  -5.877739   -6.679515   -5.5805     -6.3095336  -1.5709614  -6.4896674\n",
            "  -6.3950233  -6.5759654  -7.3665676  -5.260038   -6.7230415  -6.8924704\n",
            "  -7.187347   -8.307877   -7.5600266  -7.2732453  -7.072122   -7.746061\n",
            "  -3.8927484  -7.735509   -5.0846314  -6.6054997  -6.8543334  -6.399587\n",
            "  -6.5893393  -5.015308   -7.8152823  -8.836946   -4.448835   -7.410091\n",
            "  -4.7456417  -7.923987   -7.418981   -6.591455   -6.360106   -7.504528\n",
            "  -8.550615   -7.1849017  -8.272017   -8.582233   -7.865438   -6.9119706\n",
            "  -7.982367   -7.07346    -6.482453   -7.339108   -6.5452585  -6.6938787\n",
            "  -7.0889287  -7.2008915  -7.7829065  -7.636852   -8.251106   -7.7557325\n",
            "  -7.417692   -7.2788563  -8.633762   -8.2859955  -7.7123275  -8.211456\n",
            "  -8.6955185  -7.380481   -7.817155   -8.02154    -8.39131    -8.537285\n",
            "  -8.155713   -7.7761216  -8.584953   -8.219375   -7.51868    -8.464545\n",
            "  -8.85293    -7.7114835  -7.5703483  -8.596865   -8.623131   -7.659615\n",
            "  -7.8749433  -8.605216   -8.405449   -8.327364   -8.240112   -8.954026\n",
            "  -8.796346   -8.519293   -7.512957   -7.625858   -8.672331   -8.98503\n",
            "  -8.227223   -8.942136   -7.923723   -8.59507    -7.5914493  -8.146778\n",
            "  -8.393578   -8.396046   -8.300245   -8.335628   -9.024764   -8.397797\n",
            "  -8.602265   -8.742727   -8.398407   -8.415013   -8.922715   -8.534584\n",
            "  -8.240059   -8.847026   -8.9580765  -8.147345   -8.873987   -8.038785\n",
            "  -7.3465123  -8.57077    -8.982694   -7.9279194  -8.89045    -7.63055\n",
            "  -9.0576935  -8.587198   -6.8592157  -8.30954    -7.8519845  -8.689486\n",
            "  -8.6223     -8.642092   -9.018626   -6.8862443  -7.893632   -8.946561\n",
            "  -6.7491326  -6.54506    -8.1182165  -8.351354   -8.5258665  -8.1125965\n",
            "  -8.334705   -8.049227   -8.268706   -8.535587   -8.115629   -8.767482\n",
            "  -8.271278   -8.924759   -8.7434025  -8.426739   -7.3442388  -8.358082\n",
            "  -8.765391   -7.661696   -8.760958   -8.792164   -8.561562   -7.6117835\n",
            "  -8.317724   -7.891765   -8.66763    -8.645033   -8.817399   -8.162274\n",
            "  -8.757272   -7.7990565  -8.892851   -7.3223443  -8.147528   -7.801789\n",
            "  -8.479497   -8.272408    0.9693652 ]], shape=(1, 459), dtype=float32)\n",
            "\n",
            "\n",
            "tf.Tensor(\n",
            "[[ 1.4835657  -4.8711853  -7.394923   -7.180052    1.4835727  -7.7728057\n",
            "  -3.3518667  -4.6794415  -5.855361   -6.148092   -7.3541946  -7.054539\n",
            "  -3.5559385  -7.583563   -8.456868   -8.150661   -8.363393   -8.369367\n",
            "  -7.129613   -8.641339   -8.03896    -8.144613   -4.7941265  -4.1802883\n",
            "  -6.482338   -8.397845   -7.742262   -8.427044   -7.775312   -8.265642\n",
            "  -6.1344824  -6.815688   -8.697451   -8.13456    -8.486592   -8.16335\n",
            "  -8.158904   -6.341633   -5.971904   -7.589979   -8.399789   -8.1851015\n",
            "  -8.289141   -8.402676   -8.381251   -7.8936152  -7.6755314  -8.281342\n",
            "  -7.7649565  -6.260121   -5.21742    -5.7184553  -6.0051293  -7.389604\n",
            "  -7.1206284  -7.7395725  -7.684252   -7.1253633  -6.6207256  -8.191409\n",
            "  -8.314389   -7.8204703  -8.474641   -8.0539255  -8.180969   -6.270074\n",
            "  -8.343957   -8.060136   -6.710066   -6.326212   -8.829852   -7.6648073\n",
            "  -7.3927064  -8.443218   -7.430802   -6.032119   -7.2111645  -8.108314\n",
            "  -8.2732     -8.023487   -8.359858   -8.403337   -8.441913   -8.497689\n",
            "  -8.251062   -5.442403   -5.912831   -8.454957   -8.166789   -7.5051055\n",
            "  -7.531594   -7.2380557  -7.6198025  -7.979066   -6.6227293  -6.7420273\n",
            "  -6.9818225  -8.131906   -7.782203   -7.5974493  -6.458256   -6.888735\n",
            "  -7.6444798  -7.886137   -7.8286705  -7.6365604  -5.772479   -5.427335\n",
            "  -6.0568876  -6.305729   -5.8513145  -5.299122   -6.9107265  -8.036695\n",
            "  -7.7912755  -8.298163   -7.985647   -6.907339   -4.124726   -7.958745\n",
            "  -7.0442657  -6.520612   -3.2610235  -5.5095015  -7.622878   -6.1296115\n",
            "  -4.018147   -8.174979   -8.019113   -5.0560055  -5.134318   -7.3963485\n",
            "  -7.413606   -6.1595044  -7.9839015  -6.273075   -1.8839611  -3.6221447\n",
            "  -4.4159884  -6.6417627  -7.4785147  -7.95718    -7.8704033  -8.154843\n",
            "  -8.197385   -8.240058   -5.4199777  -6.992815   -4.948971   -7.641466\n",
            "  -2.7937486  -3.0521986  -7.520047   -8.11322    -6.9855757  -7.38172\n",
            "  -8.316623   -7.600457   -8.43631    -7.320837   -7.2950892  -4.7558665\n",
            "  -7.470717   -6.8323216  -8.321201   -7.5803804  -7.527669   -7.7483063\n",
            "  -5.789312   -6.5538054  -8.227177   -8.036233   -5.7240496  -6.401534\n",
            "  -8.202992   -8.183114   -7.541689   -7.755391   -5.309897   -5.096169\n",
            "  -7.635328   -6.8248873  -8.308038   -8.274974   -5.5605154  -7.3289785\n",
            "  -5.2681727  -5.879175   -7.183651   -5.852315   -7.1956706  -7.539883\n",
            "  -3.2204688  -4.1890526  -7.454163   -8.063821   -7.995687   -6.8223763\n",
            "  -7.20222    -6.527499   -6.4244313  -4.848566   -3.6794252  -4.864407\n",
            "  -5.873925    3.021407   -0.6013498   0.34075993 -7.067963   -6.5899057\n",
            "  -6.643323   -7.5950985  -7.4437265  -3.5295117  -6.977516   -7.252961\n",
            "  -6.965557   -2.2765734  -1.7273022  -7.4683485  -4.9158654  -7.4541326\n",
            "  -6.688384   -5.462828   -7.35036    -6.9508433  -6.51625    -5.248794\n",
            "  -6.920911   -4.2969275  -7.877768   -5.482857   -2.9677327  -3.4067154\n",
            "  -7.8443203  -7.7892137  -6.968116   -7.3308682  -6.65976    -7.7718616\n",
            "  -7.564722   -7.924704   -5.9411116  -7.9980717  -8.308864   -6.3918853\n",
            "  -2.4671676  -3.5503783  -4.941456   -7.0814476  -3.5553846  -7.485905\n",
            "  -7.9753656  -7.0739155  -4.4614     -7.776426   -7.71373    -6.879447\n",
            "  -6.5348983  -5.5519447  -7.584359   -6.293206   -4.9993525  -2.9693015\n",
            "  -2.0582912  -2.7486503  -5.07893    -6.461079   -8.754406   -8.107807\n",
            "  -8.500722   -8.82747    -8.501657   -7.4068213  -6.3458853  -8.9697895\n",
            "  -8.40858    -7.8560805  -8.423671   -8.163878   -6.38927    -8.578693\n",
            "  -8.559187   -8.03571    -8.611375   -8.185084   -5.4011736  -5.857195\n",
            "  -7.7357244  -6.6967     -6.9574757  -7.2097287  -1.187107   -8.0846\n",
            "  -7.517493   -6.1505966  -8.054564   -4.5738726  -3.9384158  -8.604552\n",
            "  -8.458333   -8.04527    -8.930474   -7.808509   -6.1233587  -6.3660345\n",
            "  -4.311139   -7.2347474  -4.950398   -7.6209083  -6.9503427  -6.6402507\n",
            "  -7.414323   -7.1670475  -4.1489577  -6.3302917  -3.8267925  -5.382496\n",
            "  -7.4968987  -8.328183   -7.9787884  -7.802165   -7.1140404  -4.2971983\n",
            "  -5.8057065  -7.652275   -8.283496   -7.8441687  -8.246461   -8.064749\n",
            "  -8.2573185  -7.7091055  -4.7401915  -4.907615   -6.768466   -8.242176\n",
            "  -7.7743425  -8.045542   -6.5706854  -8.244529   -8.048369   -5.1470366\n",
            "  -7.6524715  -8.023654   -8.213902   -7.33315    -7.4848566  -5.3111997\n",
            "  -6.7080317  -7.818228   -7.5192633  -7.9958963  -8.273495   -8.039878\n",
            "  -7.9865413  -7.6954803  -5.56444    -6.0041547  -7.8951807  -8.2631235\n",
            "  -7.604547   -8.23926    -7.985317   -6.272203   -7.7035937  -8.032668\n",
            "  -8.000626   -7.937902   -8.113463   -7.8119125  -6.427455   -8.001277\n",
            "  -8.01611    -5.7345657  -5.4928966  -8.011268   -8.248746   -7.982055\n",
            "  -7.2505054  -6.8493843  -6.838124   -6.903078   -8.273671   -8.238945\n",
            "  -7.8630404  -7.002681   -7.8554883  -7.864614   -7.2620997  -7.9533615\n",
            "  -8.198014   -8.159162   -8.0085125  -7.9552126  -7.247704   -8.298066\n",
            "  -7.960374   -8.323651   -8.264041   -7.7833195  -6.53176    -6.089778\n",
            "  -7.976109   -8.286567   -7.923385   -8.293706   -7.99137    -8.183625\n",
            "  -6.344601   -7.800885   -8.423049   -8.005099   -8.300541   -7.109023\n",
            "  -8.336194   -6.872272   -6.937586   -7.8792076  -7.7774854  -6.832748\n",
            "  -7.988835   -8.336363   -8.060902   -8.131957   -8.1538925  -8.251939\n",
            "  -8.185772   -6.604565   -8.166599   -7.887463   -7.6840005  -8.122627\n",
            "  -5.241863   -5.328496   -5.08972    -7.688479   -8.00552    -8.304284\n",
            "  -8.213954   -7.523387   -8.20321    -6.6959743  -7.918605   -8.145184\n",
            "  -8.19615    -7.7903676  -7.798173   -7.8508143  -8.032395   -8.269824\n",
            "  -8.159789   -6.6942663  -7.057744   -7.9997463  -8.130567   -7.9692745\n",
            "  -6.0646725  -5.5731697   1.4835298 ]], shape=(1, 459), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokens with highest start and end scores\n",
        "answer_start = tf.argmax(tf.cast(output.start_logits, tf.int32), axis=1)\n",
        "answer_end = tf.where(tf.equal(output.end_logits, float(tf.reduce_max(output.end_logits[0]))))[:,-1]"
      ],
      "metadata": {
        "id": "HCm7_OugieVz"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer_start, answer_end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-EMxIWAijHk",
        "outputId": "a4a0ebc5-562d-4b5a-cb31-040ec015874b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([205], shape=(1,), dtype=int64) tf.Tensor([205], shape=(1,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if answer_end >= answer_start:\n",
        "    answer = \" \".join(tokens[int(answer_start):int(answer_end)+1])\n",
        "else:\n",
        "    print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
        "    \n",
        "print(\"Text:\\n{}\".format(text.capitalize()))\n",
        "print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
        "print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN3c3mjTjmH5",
        "outputId": "db9ca5ad-e937-4518-af36-c6dac2d5a5ca"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "(cnn) -- elmore leonard is something of a living legend among lovers of crime fiction. a favorite of millions of readers, a hero to scores of writers, he's been called \"america's greatest crime writer.\" the 86-year old author has been writing bestselling books for sixty years, mostly westerns and crime novels. many of them have been turned into hit movies, including \"3:10 to yuma,\" \"get shorty\" and \"out of sight.\" \n",
            "\n",
            "now, leonard returns to one of his favorite characters in his newest book, his 45th novel to be exact, titled simply, \"raylan.\" that would be u.s. marshal raylan givens. the laid back, stetson-wearing lawman first appeared in leonard's novels, \"pronto\" and \"riding the rap\" and again in the 2001 short story, \"fire in the hole\" which became the basis for the hit tv show, \"justified,\" starring timothy olyphant as the title character. the actor and the show are winning over fans, critics and leonard himself. so much so that leonard has returned to writing about \"raylan.\" \n",
            "\n",
            "the book just hit store shelves the same week the show had its third season premiere. leonard, gracious and unassuming, shows no signs of slowing down at this point in his career. \n",
            "\n",
            "the author spoke to cnn from his home in michigan. the following is an edited transcript. \n",
            "\n",
            "cnn: what brought you back to raylan? \n",
            "\n",
            "leonard: i've always liked him. he's just one of my favorites. now when i see him on the screen i can't believe it. he acts exactly the way i write him. he's so laid back and he always has the best line in the scene. he's perfect, boy. the way he talks i hear him just the way i heard him when i'm writing it. he's kind of laid back but if you call him on anything, he says, \"if i have to pull my gun i will shoot to kill,\" and he's serious about that but he doesn't have to sound that serious, he just states it. \n",
            "\n",
            "Question:\n",
            "What show?\n",
            "\n",
            "Answer:\n",
            "Justified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[random_num]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XelxyN04jqzh",
        "outputId": "c5a87ad5-d7c5-4e0b-c997-ac239302af38"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text        (CNN) -- Elmore Leonard is something of a livi...\n",
              "question                                           What show?\n",
              "answer                                             Justified,\n",
              "Name: 29388, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = tokens[int(answer_start)]\n",
        "\n",
        "for i in range(int(answer_start)+1, int(answer_end)+1):\n",
        "    if tokens[i][0:2] == \"##\":\n",
        "        answer += tokens[i][2:]\n",
        "    else:\n",
        "        answer += \" \" + tokens[i]"
      ],
      "metadata": {
        "id": "xY6oMKyujvdq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def question_answer(question, text):\n",
        "    \n",
        "    #tokenize question and text in ids as a pair\n",
        "    input_ids = tokenizer(question, text, return_tensors=\"tf\")\n",
        "    \n",
        "    #string version of tokenized ids\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids.input_ids[0])\n",
        "    \n",
        "    #model output using input_ids and segment_ids\n",
        "    output = model(input_ids)\n",
        "    \n",
        "    #reconstructing the answer\n",
        "    answer_start = tf.argmax(tf.cast(output.start_logits, tf.int32), axis=1)\n",
        "    answer_end = tf.where(tf.equal(output.end_logits, float(tf.reduce_max(output.end_logits[0]))))[:,-1]\n",
        "\n",
        "    if answer_end >= answer_start:\n",
        "        answer = tokens[int(answer_start)]\n",
        "        for i in range(int(answer_start)+1, int(answer_end)+1):\n",
        "            if tokens[i][0:2] == \"##\":\n",
        "                answer += tokens[i][2:]\n",
        "            else:\n",
        "                answer += \" \" + tokens[i]\n",
        "                \n",
        "    if answer.startswith(\"[CLS]\"):\n",
        "        answer = \"Unable to find the answer to your question.\"\n",
        "    \n",
        "    print(\"\\nAnswer:\\n{}\".format(answer.capitalize()))"
      ],
      "metadata": {
        "id": "IB703hf4jz4P"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "New York (CNN) -- More than 80 Michael Jackson collectibles -- including the late pop star's famous rhinestone-studded glove from a 1983 performance -- were \n",
        "auctioned off Saturday, reaping a total $2 million. Profits from the auction at the Hard Rock Cafe in New York's Times Square crushed pre-sale expectations of \n",
        "only $120,000 in sales. The highly prized memorabilia, which included items spanning the many stages of Jackson's career, came from more than 30 fans, \n",
        "associates and family members, who contacted Julien's Auctions to sell their gifts and mementos of the singer. Jackson's flashy glove was the big-ticket item \n",
        "of the night, fetching $420,000 from a buyer in Hong Kong, China. Jackson wore the glove at a 1983 performance during \\\"Motown 25,\\\" an NBC special where he \n",
        "debuted his revolutionary moonwalk. Fellow Motown star Walter \\\"Clyde\\\" Orange of the Commodores, who also performed in the special 26 years ago, said he \n",
        "asked for Jackson's autograph at the time, but Jackson gave him the glove instead. \"The legacy that [Jackson] left behind is bigger than life for \n",
        "me,\\\" Orange said. \\\"I hope that through that glove people can see what he was trying to say in his music and what he said in his music.\\\" Orange said \n",
        "he plans to give a portion of the proceeds to charity. Hoffman Ma, who bought the glove on behalf of Ponte 16 Resort in Macau, paid a 25 percent buyer's \n",
        "premium, which was tacked onto all final sales over $50,000. Winners of items less than $50,000 paid a 20 percent premium.\n",
        "\"\"\"\n",
        "\n",
        "question = \"Where was the Auction held?\""
      ],
      "metadata": {
        "id": "AlMeAQ2xj5mG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_answer(question, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBZTo5SNj9Vg",
        "outputId": "04c56d35-08f0-45b3-fd72-61a39b1814d0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer:\n",
            "The hard rock cafe in new york ' s times square\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original answer:\\n\", data.loc[data[\"question\"] == question][\"answer\"].values[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByHDYQedkBGK",
        "outputId": "27a6e2d7-35db-4039-8d9c-67d5d323f6cc"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original answer:\n",
            " Hard Rock Cafe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"How is called the place where was done the Auction?\"\n",
        "question_answer(question, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9gEid9mkER8",
        "outputId": "fab7b8f1-c6ca-4ae7-8abb-512e684d3808"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer:\n",
            "Hard rock cafe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = \"\"\"\n",
        "Seth Rollins won the WWE World Heavyweight Championship in the main event at Wrestlemania 31 in the Levi's stadium that attended \n",
        "over 100000 people, in a fantastic cashing of The Money In The Bank contract in a heartstopping moment where both fighter were\n",
        "absolutely hurted. The Undertaker made his return and continued succesfully his streak by defeating Bray Wyatt in a tough match.\n",
        "John Cena defeated Rusev for the US Championship in a match that became into a battle of nations and \n",
        "at moments polemic. One of the dream match all fans loved to see is the battle of two of the greatest teams in the industry: NWO vs DX, \n",
        "being represented by Sting and Triple H respectively.\n",
        "Vince McMahon (WWE's chairman) said: The event was a success and left satisfied the fans because of the surprise factor and the perfect performance\n",
        "of all superstars. Nevertheless there are plans for tomorrow at monday night RAW where the former champion Brock Lesnar\n",
        "will have a rematch for the title. \"\"\""
      ],
      "metadata": {
        "id": "YRN-SbdskGzS"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\"Who won WWE championship?\",\n",
        "             \"How many people attented Wrestlemania 31?\",\n",
        "             \"Who made his return at the event?\",\n",
        "             \"Who represented NWO?\",\n",
        "             \"Who represented DX?\",\n",
        "             \"Who is WWE's chairman?\",\n",
        "             \"What title won John Cena?\",\n",
        "             \"When is will be monday night RAW?\",\n",
        "             \"Why the event was a success?\",\n",
        "             \"What will happen at RAW live event?\"]"
      ],
      "metadata": {
        "id": "FppkILxXkLDJ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for quest in questions:\n",
        "    question_answer(quest, text2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ4us2xgkNeE",
        "outputId": "31527da8-2681-456f-d2e6-ab79aa9e6139"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer:\n",
            "Seth rollins\n",
            "\n",
            "Answer:\n",
            "Over 100000\n",
            "\n",
            "Answer:\n",
            "The undertaker\n",
            "\n",
            "Answer:\n",
            "Sting\n",
            "\n",
            "Answer:\n",
            "Triple h\n",
            "\n",
            "Answer:\n",
            "Vince mcmahon\n",
            "\n",
            "Answer:\n",
            "Us championship\n",
            "\n",
            "Answer:\n",
            "Tomorrow\n",
            "\n",
            "Answer:\n",
            "The surprise factor and the perfect performance of all superstars\n",
            "\n",
            "Answer:\n",
            "Brock lesnar will have a rematch for the title\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Please enter your text: \\n\")\n",
        "question = input(\"\\nPlease enter your question: \\n\")\n",
        "\n",
        "while True:\n",
        "    question_answer(question, text)\n",
        "    \n",
        "    flag = True\n",
        "    flag_N = False\n",
        "    \n",
        "    while flag:\n",
        "        response = input(\"\\nDo you want to ask another question based on this text (Y/N)? \")\n",
        "        if response[0] == \"Y\":\n",
        "            question = input(\"\\nPlease enter your question: \\n\")\n",
        "            flag = False\n",
        "        elif response[0] == \"N\":\n",
        "            print(\"\\nBye!\")\n",
        "            flag = False\n",
        "            flag_N = True\n",
        "            \n",
        "    if flag_N == True:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10obZdgnkPRY",
        "outputId": "d94e23c5-6afa-439f-9af7-aa1c6b4fce58"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your text: \n",
            "hello\n",
            "\n",
            "Please enter your question: \n",
            "hi\n",
            "\n",
            "Answer:\n",
            "Hi [sep]\n",
            "\n",
            "Do you want to ask another question based on this text (Y/N)? y\n",
            "\n",
            "Do you want to ask another question based on this text (Y/N)? what is\n",
            "\n",
            "Do you want to ask another question based on this text (Y/N)? Y\n",
            "\n",
            "Please enter your question: \n",
            "what is war?\n",
            "\n",
            "Answer:\n",
            "Unable to find the answer to your question.\n",
            "\n",
            "Do you want to ask another question based on this text (Y/N)? Y\n",
            "\n",
            "Please enter your question: \n",
            "kk\n",
            "\n",
            "Answer:\n",
            "Kk [sep]\n",
            "\n",
            "Do you want to ask another question based on this text (Y/N)? N\n",
            "\n",
            "Bye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "am4g_EkokVjD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}